{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ltSF60Co6vJ4"
      ],
      "authorship_tag": "ABX9TyORGuZSar9by9eEqkKUcGhk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelofschiavo/ds-cookbook/blob/main/05_ML_Classificacao_(Supervisionado).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05. Modelagem Preditiva (Classifica√ß√£o)\n",
        "\n",
        "Nos notebooks anteriores, n√≥s *entendemos* o passado (com EDA e Estat√≠stica).\n",
        "Agora, vamos *prever* o futuro.\n",
        "\n",
        "**Objetivo:** Criar um modelo de Machine Learning que aprenda com os dados de quem *saiu* e *ficou* para prever, com base em um funcion√°rio novo (ou existente), qual a **probabilidade** dele pedir demiss√£o.\n",
        "\n",
        "**Tipo de Problema:** Classifica√ß√£o Bin√°ria (prever uma categoria: \"Sim\" ou \"N√£o\")."
      ],
      "metadata": {
        "id": "ltSF60Co6vJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "## Setup: Carregar Bibliotecas e Dados\n",
        "\n",
        "Nesta c√©lula, importamos as bibliotecas que usaremos (Pandas e Scikit-learn)\n",
        "e carregamos nosso conjunto de dados limpo do Notebook 01.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos futuros (apenas para limpar o output)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Carregue seus dados aqui ---\n",
        "# (Substitua 'dados_empresa_limpos.csv' pelo nome do seu arquivo)\n",
        "try:\n",
        "    df = pd.read_csv('dados_empresa_limpos.csv')\n",
        "    print(\"DataFrame 'df' carregado com sucesso!\")\n",
        "    print(f\"Total de {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    print(\">>> ERRO: Arquivo 'dados_empresa_limpos.csv' n√£o encontrado. <<<\")\n",
        "    print(\"... Criando um DataFrame de EXEMPLO para o resto do notebook n√£o quebrar.\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "\n",
        "    # Criar um 'df' de exemplo para classifica√ß√£o\n",
        "    data = {\n",
        "        'salario': np.random.randint(3000, 15000, 500),\n",
        "        'satisfacao': np.random.rand(500).round(2),\n",
        "        'tempo_empresa': np.random.randint(1, 10, 500),\n",
        "        'departamento': np.random.choice(['TI', 'Vendas', 'RH'], 500),\n",
        "        'pediu_demissao': np.random.choice([0, 1], 500, p=[0.85, 0.15]) # 15% de turnover\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"DataFrame de exemplo carregado.\")\n",
        "\n",
        "print(\"\\nAmostra dos dados:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "S5VACGFJ4o01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 1: Prepara√ß√£o (Separar X/y e One-Hot Encoding)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Modelos de ML s√£o √≥timos em matem√°tica, mas p√©ssimos em ler texto. N√£o podemos dar a ele a coluna 'departamento' com 'TI' ou 'Vendas'. Precisamos 'traduzir':\n",
        "1.  **Separar:** Dizemos ao modelo o que ele precisa prever (o 'y': `pediu_demissao`) e quais 'pistas' ele pode usar (o 'X': todas as outras colunas).\n",
        "2.  **Traduzir:** Transformamos 'departamento' em colunas num√©ricas, como 'departamento_TI' (1 se sim, 0 se n√£o) e 'departamento_Vendas' (1 se sim, 0 se n√£o).\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "Realizamos duas opera√ß√µes:\n",
        "1.  **Separa√ß√£o de Features e Target:** `y` √© o vetor-alvo (vari√°vel dependente, `pediu_demissao`) e `X` √© a matriz de features (vari√°veis independentes, preditores).\n",
        "2.  **One-Hot Encoding:** Usamos `pd.get_dummies()` para converter vari√°veis categ√≥ricas nominais (como `departamento`) em N colunas bin√°rias, onde N √© o n√∫mero de categorias √∫nicas. Isso evita que o modelo assuma uma ordem incorreta (ex: que TI < Vendas < RH).\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "nTs2bg5HveMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Definir X (features) e y (target)\n",
        "#    (Assumindo que 'pediu_demissao' √© 1 para Sim e 0 para N√£o)\n",
        "y = df['pediu_demissao']\n",
        "X = df.drop('pediu_demissao', axis=1) # Usar todas as outras colunas como features\n",
        "\n",
        "# 2. One-Hot Encoding (Converter categorias em n√∫meros)\n",
        "#    O 'drop_first=True' evita redund√¢ncia e multicolinearidade\n",
        "X_encoded = pd.get_dummies(X, drop_first=True, dtype=int)\n",
        "\n",
        "print(\"--- Target (y) ---\")\n",
        "print(y.head())\n",
        "print(\"\\n--- Features (X_encoded) ---\")\n",
        "print(X_encoded.head())"
      ],
      "metadata": {
        "id": "JHAizSXovfp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Agora temos 'y' (uma S√©rie s√≥ com 0s e 1s) e 'X_encoded' (um DataFrame s√≥ com n√∫meros, pronto para o modelo).\""
      ],
      "metadata": {
        "id": "e1Q0QSfI48x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 2: Divis√£o de Treino e Teste (train_test_split)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Nunca podemos testar um aluno usando a mesma prova que ele usou para estudar. Ele iria 'decorar' as respostas, n√£o 'aprender' o conceito.\n",
        "Com ML √© igual. N√≥s dividimos nosso 'baralho' de dados:\n",
        "* **70% para Treino:** As 'aulas' e 'exerc√≠cios' que o modelo usa para aprender os padr√µes.\n",
        "* **30% para Teste:** A 'prova final'. Dados que o modelo *nunca viu*, usados para ver se ele realmente aprendeu a generalizar.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "Particionamos os dados (X e y) em conjuntos de treino e teste. Isso √© vital para avaliar a capacidade de **generaliza√ß√£o** do modelo em dados \"novos\" (out-of-sample).\n",
        "* `test_size=0.3`: Reserva 30% dos dados para o teste.\n",
        "* `random_state=42`: Garante a **reprodutibilidade**. A divis√£o ser√° sempre a mesma, n√£o importa quantas vezes rodarmos.\n",
        "* `stratify=y`: **CRUCIAL** em classifica√ß√£o desbalanceada (como turnover). Garante que a propor√ß√£o de 'Sim' e 'N√£o' (ex: 15% de 'Sim') seja a mesma tanto no conjunto de treino quanto no de teste.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "6D0H8bN6vhX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded, y,\n",
        "    test_size=0.30,\n",
        "    random_state=42,\n",
        "    stratify=y  # Essencial para garantir propor√ß√µes iguais de 'y' no treino/teste\n",
        ")\n",
        "print(f\"Shape de X_train: {X_train.shape}\")\n",
        "print(f\"Shape de X_test:  {X_test.shape}\")\n",
        "print(\"-\" * 20)\n",
        "print(f\"Propor√ß√£o de 'Sair' no Treino: {y_train.mean():.2%}\")\n",
        "print(f\"Propor√ß√£o de 'Sair' no Teste:  {y_test.mean():.2%}\")"
      ],
      "metadata": {
        "id": "Assv2V-QvmT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Nossos dados est√£o divididos. O modelo treinar√° com as amostras de 'treino' e ser√° avaliado com as amostras de 'teste'.\""
      ],
      "metadata": {
        "id": "btEwwBwB5LAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 3: Feature Scaling (StandardScaler) - (Opcional, mas recomendado)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Alguns modelos (como a Regress√£o Log√≠stica) s√£o 'enganados' por escalas diferentes. A coluna 'salario' (Ex: 3000 a 15000) parece *milhares* de vezes mais importante que 'satisfacao' (Ex: 0 a 1), mesmo que n√£o seja.\n",
        "O 'Scaler' age como um 'equalizador': ele coloca todas as features na mesma r√©gua (m√©dia 0, desvio padr√£o 1), garantindo uma compara√ß√£o justa.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "A Padroniza√ß√£o (Standardization) transforma os dados para que tenham m√©dia 0 e desvio padr√£o 1 (Z-score). √â crucial para algoritmos sens√≠veis √† escala (Regress√£o Log√≠stica, SVMs, KNN, Redes Neurais).\n",
        "**IMPORTANTE (Evitar Data Leakage):** O scaler deve ser treinado (`.fit()`) **APENAS** nos dados de treino (`X_train`) e depois usado para transformar (`.transform()`) ambos (`X_train` e `X_test`).\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "SInHP-Qbvm6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Criar o Scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# 2. Treinar (fit) o scaler APENAS no X_train\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 3. Aplicar (transform) o scaler em ambos os conjuntos\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"M√©dia de X_train (antes): {X_train['salario'].mean():.2f}\")\n",
        "print(f\"M√©dia de X_train_scaled (depois): {X_train_scaled[:, 0].mean():.2f}\") # Pega a primeira coluna\n",
        "print(f\"Desvio Padr√£o de X_train_scaled (depois): {X_train_scaled[:, 0].std():.2f}\")"
      ],
      "metadata": {
        "id": "BxI3dVd25TIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Os dados de treino e teste agora est√£o escalados. Note como a m√©dia de 'X_train_scaled' √© ~0 e o desvio padr√£o √© ~1.\""
      ],
      "metadata": {
        "id": "BPBW2Xor5YAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 4: Modelo 1 - Regress√£o Log√≠stica (O Baseline)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"√â o modelo 'baseline', o mais simples e r√°pido. Ele acha a melhor 'linha' (ou curva sigm√≥ide) que separa os 'Sim' dos 'N√£o'. √â √≥timo para ter um resultado r√°pido e para ser um ponto de partida (se um modelo complexo n√£o for muito melhor que esse, talvez n√£o valha a pena us√°-lo).\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "A Regress√£o Log√≠stica √© um modelo linear generalizado usado para classifica√ß√£o bin√°ria. Ele modela a *probabilidade* de uma classe (P(y=1)) usando a fun√ß√£o log√≠stica (sigm√≥ide).\n",
        "* `class_weight='balanced'`: Ajusta os pesos do modelo para dar mais import√¢ncia √† classe minorit√°ria (no nosso caso, 'pediu_demissao'=1), o que √© vital para dados desbalanceados.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "yspXKw0B5aGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Criar o modelo\n",
        "#    Usamos 'class_weight='balanced'' para o modelo dar mais import√¢ncia\n",
        "#    aos casos de 'Sim' (turnover), que geralmente s√£o minoria.\n",
        "log_reg = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "\n",
        "# 2. Treinar o modelo (usando dados ESCALADOS)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 3. Fazer previs√µes (nos dados de teste ESCALADOS)\n",
        "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
        "\n",
        "print(\"Previs√µes da Regress√£o Log√≠stica (primeiros 10):\")\n",
        "print(y_pred_log_reg[:10])"
      ],
      "metadata": {
        "id": "UCJtl-FA5el2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Modelo treinado. As previs√µes est√£o na vari√°vel 'y_pred_log_reg'. Vamos avali√°-las no pr√≥ximo passo.\""
      ],
      "metadata": {
        "id": "cJQow3ta5jHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 5: Modelo 2 - Random Forest (O \"Cavalo de Batalha\")\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"√â o 'cavalo de batalha' do ML. Em vez de uma pessoa tentando decidir, ele pergunta a 100 'especialistas' (√Årvores de Decis√£o) e faz uma *vota√ß√£o* entre elas. Cada 'especialista' v√™ o problema de um √¢ngulo um pouco diferente. O resultado da 'vota√ß√£o' √© muito mais robusto e preciso.\n",
        "**B√¥nus:** Modelos de √°rvore n√£o se importam com a escala dos dados (n√£o precisam do Scaler).\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "O Random Forest √© um m√©todo *ensemble* de *bagging*. Ele constr√≥i m√∫ltiplas √°rvores de decis√£o em tempo de treino, cada uma em uma sub-amostra aleat√≥ria dos dados (bootstrap). A previs√£o final √© a *moda* (vota√ß√£o) das previs√µes de todas as √°rvores. √â robusto a overfitting e captura rela√ß√µes n√£o-lineares complexas.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "27SyQv535m0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. Criar o modelo\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,  # Quantidade de √°rvores na \"floresta\"\n",
        "    random_state=42,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1          # Usar todos os processadores\n",
        ")\n",
        "\n",
        "# 2. Treinar o modelo (usando dados ORIGINAIS, n√£o escalados)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Fazer previs√µes (nos dados de teste ORIGINAIS)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "print(\"Previs√µes do Random Forest (primeiros 10):\")\n",
        "print(y_pred_rf[:10])"
      ],
      "metadata": {
        "id": "OVNDOlGH5nwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Modelo treinado. As previs√µes est√£o na vari√°vel 'y_pred_rf'. Agora vamos comparar os dois modelos.\""
      ],
      "metadata": {
        "id": "Esgu96e95xG7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 6: Avalia√ß√£o (Classification Report & Confusion Matrix)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Em turnover, 'Acur√°cia' (acertos totais) √© in√∫til. Um modelo que chuta 'Fica' para todos acerta 90% das vezes (se 10% saem), mas n√£o serve para nada. Precisamos focar nas m√©tricas certas:\n",
        "* **Recall (para classe 1 'Sair'):** 'De todas as pessoas que *realmente* v√£o sair, quantas o nosso modelo conseguiu *pegar*?' (Esta √© a m√©trica-chave para o RH!).\n",
        "* **Precis√£o (para classe 1 'Sair'):** 'De todos que o modelo *acusou* que iam sair, quantos realmente sa√≠ram?' (Importante para n√£o gastar recursos de reten√ß√£o com quem ia ficar).\"\n",
        "\n",
        "A **Matriz de Confus√£o** √© o 'raio-X' dos erros. O pior erro √© o **Falso Negativo**: a pessoa *vai sair* (Real=1) e o modelo previu que ela ia *ficar* (Previsto=0).\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "* **`classification_report`**: Fornece um resumo das principais m√©tricas (Precis√£o, Recall, F1-Score) por classe. O F1-Score √© a m√©dia harm√¥nica de Precis√£o e Recall, √∫til como m√©trica √∫nica.\n",
        "* **`confusion_matrix`**: Uma tabela que resume o desempenho:\n",
        "    * **TN (Topo Esquerdo):** Previu '0', Real '0'.\n",
        "    * **FP (Topo Direita):** Previu '1', Real '0'. (Erro Tipo I)\n",
        "    * **FN (Baixo Esquerda):** Previu '0', Real '1'. (Erro Tipo II - O mais cr√≠tico!)\n",
        "    * **TP (Baixo Direita):** Previu '1', Real '1'.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "1OMCZU_k51MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Vamos avaliar o Random Forest (y_pred_rf), que geralmente √© melhor.\n",
        "print(\"--- Classification Report (Random Forest) ---\")\n",
        "# 'target_names' deixa o relat√≥rio mais leg√≠vel\n",
        "print(classification_report(y_test, y_pred_rf, target_names=['Ficou (0)', 'Saiu (1)']))\n",
        "\n",
        "\n",
        "# --- Matriz de Confus√£o ---\n",
        "print(\"\\n--- Matriz de Confus√£o (Random Forest) ---\")\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "# Plotar a matriz\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Ficou (0)', 'Saiu (1)'])\n",
        "disp.plot(cmap='Blues', values_format='d') # 'd' = formato decimal\n",
        "plt.title('Matriz de Confus√£o')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HiBqdfA559FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"No Classification Report, olhe para a linha 'Saiu (1)'. Um **Recall de 0.70** significaria que estamos 'pegando' 70% das pessoas que realmente v√£o pedir demiss√£o.\n",
        "Na Matriz de Confus√£o, o n√∫mero no canto **inferior esquerdo** s√£o os Falsos Negativos (as pessoas que perdemos). Nosso objetivo √© minimizar esse n√∫mero.\""
      ],
      "metadata": {
        "id": "HVDDLBB26CIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 7: Interpreta√ß√£o (Feature Importance)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"OK, o modelo do Random Forest √© uma 'caixa-preta' que acerta bastante. Mas *por qu√™*? Ele n√£o pode simplesmente dizer 'prevejo que ele vai sair' sem uma explica√ß√£o.\n",
        "A 'Import√¢ncia das Features' nos diz quais 'pistas' (colunas) o modelo mais usou para tomar suas decis√µes. Ele nos diz o 'O Qu√™' do porqu√™ (Ex: 'Sal√°rio' √© o mais importante), dando um foco de a√ß√£o para o RH.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "Em modelos de √°rvore (como o Random Forest), podemos extrair o `feature_importances_`. Esta √© uma medida (geralmente *Gini importance*) que calcula o quanto cada feature contribuiu, em m√©dia, para a redu√ß√£o da impureza (ou aumento da 'pureza' dos n√≥s) ao longo de todas as√°rvores da floresta.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "fSscBdzV6Hho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# 1. Pegar as import√¢ncias do modelo treinado\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# 2. Criar um DataFrame para visualiza√ß√£o\n",
        "#    Usamos X_encoded.columns para pegar os nomes das features\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X_encoded.columns,\n",
        "    'Importance': importances\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 3. Plotar as 10 mais importantes\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    data=feature_importance_df.head(10),\n",
        "    palette='viridis'\n",
        ")\n",
        "plt.title('Top 10 Features Mais Importantes (Random Forest)')\n",
        "plt.xlabel('Import√¢ncia')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m9FcEzMw6NTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"O gr√°fico confirma visualmente quais s√£o os principais *drivers* do turnover. Se 'satisfacao', 'salario' e 'tempo_empresa' est√£o no topo, isso valida nossas suspeitas da EDA e da Estat√≠stica, e d√° ao RH um foco claro de atua√ß√£o para pol√≠ticas de reten√ß√£o.\""
      ],
      "metadata": {
        "id": "zTpV1Pid6SFi"
      }
    }
  ]
}