{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP21sXXh1M8k8C7B40NzigU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelofschiavo/ds-cookbook/blob/main/07_ML_Clustering_(Nao_Supervisionado).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07. Aprendizado N√£o Supervisionado (Clustering)\n",
        "\n",
        "Nos notebooks 05 e 06 (Supervisionados), n√≥s t√≠nhamos um 'gabarito' (a coluna 'y', como 'pediu_demissao' ou 'salario') e o modelo aprendia a prever esse gabarito.\n",
        "\n",
        "Aqui, no N√£o Supervisionado, **n√£o temos gabarito**.\n",
        "Nosso objetivo √© dar os dados \"bagun√ßados\" ao modelo e pedir: \"Encontre grupos naturais aqui\".\n",
        "\n",
        "**Objetivo:** Segmentar os funcion√°rios em \"Personas\" distintas (grupos) com base em seus comportamentos e atributos (Ex: 'Sal√°rio', 'Satisfa√ß√£o', 'Tempo de Empresa'), para que o RH possa criar a√ß√µes de engajamento direcionadas.\n",
        "\n",
        "**Tipo de Problema:** Clustering (Agrupamento)."
      ],
      "metadata": {
        "id": "jaOY2Haa-hcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "## Setup: Carregar Bibliotecas e Dados\n",
        "\n",
        "Nesta c√©lula, importamos as bibliotecas que usaremos (Pandas e Scikit-learn).\n",
        "O 'KMeans' e 'silhouette_score' s√£o novos aqui.\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score # M√©trica de avalia√ß√£o de cluster\n",
        "import warnings\n",
        "\n",
        "# Ignorar avisos futuros (apenas para limpar o output)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Carregue seus dados aqui ---\n",
        "# (Substitua 'dados_empresa_limpos.csv' pelo nome do seu arquivo)\n",
        "try:\n",
        "    df = pd.read_csv('dados_empresa_limpos.csv')\n",
        "    print(\"DataFrame 'df' carregado com sucesso!\")\n",
        "    print(f\"Total de {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    print(\">>> ERRO: Arquivo 'dados_empresa_limpos.csv' n√£o encontrado. <<<\")\n",
        "    print(\"... Criando um DataFrame de EXEMPLO para o resto do notebook n√£o quebrar.\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "\n",
        "    # Criar um 'df' de exemplo para clustering\n",
        "    data = {\n",
        "        'salario': np.random.randint(3000, 15000, 500),\n",
        "        'satisfacao': np.random.rand(500).round(2),\n",
        "        'tempo_empresa': np.random.randint(1, 10, 500),\n",
        "        'avaliacao_performance': np.random.rand(500).round(2),\n",
        "        'departamento': np.random.choice(['TI', 'Vendas', 'RH'], 500),\n",
        "        'pediu_demissao': np.random.choice([0, 1], 500, p=[0.85, 0.15])\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"DataFrame de exemplo carregado.\")\n",
        "\n",
        "print(\"\\nAmostra dos dados:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "sXWtkoRN-mAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 1: Prepara√ß√£o (Escolha das Features e Scaling)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Primeiro, escolhemos os 'ingredientes' das nossas personas. O que define um funcion√°rio? Vamos usar `salario`, `satisfacao` e `tempo_empresa`.\n",
        "Segundo (e **CR√çTICO**): o K-Means (nosso modelo) funciona medindo *dist√¢ncia*. Para ele, uma varia√ß√£o de R$ 1000 no sal√°rio parece *infinitamente* maior que uma varia√ß√£o de 0.1 na satisfa√ß√£o.\n",
        "Precisamos 'equalizar' (padronizar) todas as colunas, colocando-as na mesma r√©gua, para que o modelo as trate com pesos justos.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "1.  **Sele√ß√£o de Features:** Escolhemos as vari√°veis quantitativas que far√£o sentido para a segmenta√ß√£o.\n",
        "2.  **One-Hot Encoding:** Se quisermos usar `departamento`, precisamos transform√°-lo em n√∫meros (dummies) como antes.\n",
        "3.  **Padroniza√ß√£o (StandardScaler):** O K-Means usa Dist√¢ncia Euclidiana, sendo, portanto, *altamente sens√≠vel* √† escala das features. A padroniza√ß√£o (m√©dia 0, desvio 1) √© **obrigat√≥ria** para que features com escalas maiores (como 'salario') n√£o dominem o algoritmo.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "E42bA9OU-oUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Selecionar as features que definem as personas\n",
        "features_para_cluster = [\n",
        "    'salario',\n",
        "    'satisfacao',\n",
        "    'tempo_empresa',\n",
        "    'avaliacao_performance'\n",
        "]\n",
        "# Vamos adicionar 'departamento' tamb√©m, para mostrar o encoding\n",
        "df_cluster = pd.get_dummies(df[features_para_cluster + ['departamento']], drop_first=True, dtype=int)\n",
        "\n",
        "\n",
        "# 2. Padronizar TODAS as features (StandardScaler)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(df_cluster)\n",
        "\n",
        "print(\"Shape dos dados escalados:\", X_scaled.shape)\n",
        "print(\"\\nAmostra dos dados escalados (primeiras 5 linhas):\")\n",
        "print(X_scaled[:5])"
      ],
      "metadata": {
        "id": "PLYoTyii-vvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Temos uma matriz 'X_scaled' (um array NumPy) onde todas as colunas t√™m m√©dia ~0 e desvio padr√£o 1, prontas para o K-Means.\""
      ],
      "metadata": {
        "id": "6Y6fyPJ7-j5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 2: Encontrando o 'K' (Elbow Method / M√©todo do Cotovelo)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Qual o n√∫mero ideal de 'Personas' (clusters)? 2? 3? 5?\n",
        "O 'M√©todo do Cotovelo' √© um teste para nos ajudar a decidir. Ele roda o algoritmo v√°rias vezes (com K=1, K=2, K=3, ...) e mede o 'erro' (in√©rcia) de cada um.\n",
        "N√≥s plotamos esse erro. No come√ßo, o erro cai *muito* (passar de 1 para 2 grupos ajuda). Mas em certo ponto, adicionar mais grupos n√£o ajuda tanto. Esse ponto de 'retorno decrescente' √© o 'cotovelo' (Elbow) e √© um √≥timo candidato para K.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "O **Elbow Method** √© uma heur√≠stica para encontrar o n√∫mero √≥timo de clusters (K). Ele plota a **In√©rcia** (ou WCSS - Within-Cluster Sum of Squares) em fun√ß√£o do n√∫mero de clusters (K). A In√©rcia √© a soma das dist√¢ncias ao quadrado de cada ponto at√© o centro do seu cluster. Procuramos o \"cotovelo\" (joelho) da curva, que √© o ponto onde o WCSS come√ßa a diminuir mais lentamente.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "wzUoSxQo-5QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "inertia_list = []\n",
        "K_range = range(1, 11) # Vamos testar de 1 a 10 clusters\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(\n",
        "        n_clusters=k,\n",
        "        init='k-means++', # M√©todo inteligente para espalhar os centros iniciais\n",
        "        random_state=42,\n",
        "        n_init=10 # Rodar 10x com centros diferentes e pegar o melhor\n",
        "    )\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia_list.append(kmeans.inertia_) # 'inertia_' √© o WCSS\n",
        "\n",
        "# Plotar o gr√°fico do cotovelo\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K_range, inertia_list, 'bx-') # 'bx-' = linha azul com marcadores 'x'\n",
        "plt.xlabel('N√∫mero de Clusters (K)')\n",
        "plt.ylabel('In√©rcia (WCSS)')\n",
        "plt.title('M√©todo do Cotovelo (Elbow Method)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pL5_zxGe-8pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Olhe o gr√°fico. Onde a 'queda' para de ser √≠ngreme e vira um 'cotovelo'? Geralmente √© em K=3, K=4 ou K=5. Vamos supor que o cotovelo mais claro foi em **K=4**. Vamos usar K=4 para o nosso modelo final.\""
      ],
      "metadata": {
        "id": "7xRgVJim-_MU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 3: Treinando o Modelo Final (K-Means)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Agora que escolhemos nosso K (ex: K=4) no M√©todo do Cotovelo, rodamos o K-Means uma √∫ltima vez.\n",
        "O algoritmo faz o seguinte:\n",
        "1. Joga 4 '√≠m√£s' (centroides) aleat√≥rios nos nossos dados.\n",
        "2. Cada ponto de dado √© 'puxado' para o √≠m√£ mais pr√≥ximo.\n",
        "3. O '√≠m√£' se move para o centro dos pontos que ele puxou.\n",
        "4. Repete (2 e 3) at√© que os grupos n√£o mudem mais.\n",
        "No final, temos nossos 4 grupos (clusters) formados.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "Instanciamos e treinamos (com `.fit()`) o modelo K-Means usando o n√∫mero de clusters (K) escolhido. O `n_init=10` √© importante: ele roda o algoritmo 10 vezes com posi√ß√µes iniciais diferentes e escolhe a melhor (menor in√©rcia), evitando cair em um \"√≥timo local\" ruim. Ap√≥s o `.fit()`, os r√≥tulos dos clusters (0, 1, 2, 3) estar√£o dispon√≠veis em `kmeans.labels_`.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "IHH1TfkG_ALs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos definir o K escolhido (ex: 4)\n",
        "K_ESCOLHIDO = 4\n",
        "\n",
        "# 1. Criar o modelo final\n",
        "kmeans_final = KMeans(\n",
        "    n_clusters=K_ESCOLHIDO,\n",
        "    init='k-means++',\n",
        "    random_state=42,\n",
        "    n_init=10\n",
        ")\n",
        "\n",
        "# 2. Treinar e obter os r√≥tulos (labels)\n",
        "cluster_labels = kmeans_final.fit_predict(X_scaled)\n",
        "\n",
        "# 3. Adicionar os r√≥tulos de volta ao DataFrame *original*\n",
        "#    Isso √© vital para a interpreta√ß√£o!\n",
        "df_original_com_clusters = df.copy()\n",
        "df_original_com_clusters['Cluster'] = cluster_labels\n",
        "\n",
        "print(f\"Contagem de pessoas em cada Cluster (K={K_ESCOLHIDO}):\")\n",
        "print(df_original_com_clusters['Cluster'].value_counts().sort_index())\n",
        "print(\"\\nAmostra do DataFrame com Clusters:\")\n",
        "print(df_original_com_clusters.head())"
      ],
      "metadata": {
        "id": "4A4iMF6e_Ff4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Nosso DataFrame original agora tem uma nova coluna 'Cluster' (com valores de 0 a 3), dizendo a qual persona cada funcion√°rio pertence.\""
      ],
      "metadata": {
        "id": "uvlqhS2S_IOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 4: Avalia√ß√£o (Silhouette Score)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"O 'cotovelo' foi meio subjetivo. Ser√° que K=4 foi *realmente* bom?\n",
        "O 'Silhouette Score' √© uma nota de -1 a +1 que nos diz o qu√£o bons s√£o os clusters.\n",
        "* **+1:** Perfeito! Clusters s√£o densos (pontos pr√≥ximos) e muito bem separados (longe uns dos outros).\n",
        "* **0:** Ruim. Clusters est√£o sobrepostos, os grupos n√£o s√£o claros.\n",
        "* **-1:** P√©ssimo. Os pontos foram parar no cluster errado.\n",
        "Queremos o valor mais pr√≥ximo de +1 poss√≠vel.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "O Coeficiente de Silhueta (`silhouette_score`) mede a qualidade do clustering. Ele calcula para cada ponto:\n",
        "a) A dist√¢ncia m√©dia para os pontos no *mesmo* cluster (coes√£o).\n",
        "b) A dist√¢ncia m√©dia para os pontos no cluster *mais pr√≥ximo* (separa√ß√£o).\n",
        "O score √© $(b - a) / max(a, b)$. Um 'a' pequeno e um 'b' grande (score perto de 1) √© o ideal.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "kAcqhE_g_JDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Usamos os dados ESCALADOS e os r√≥tulos (labels) que o K-Means gerou\n",
        "score = silhouette_score(X_scaled, cluster_labels)\n",
        "print(f\"O Silhouette Score para K={K_ESCOLHIDO} foi de: {score:.4f}\")"
      ],
      "metadata": {
        "id": "NUs5k9hg_Mx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"Um score de 0.5 a 0.7 √© considerado um clustering forte. Um score de 0.2 a 0.4 √© razo√°vel/fraco. Abaixo de 0.2, os clusters n√£o s√£o bem definidos.\""
      ],
      "metadata": {
        "id": "2uk-goWF_RQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 5: Interpreta√ß√£o (Criando as Personas)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Esta √© a parte mais importante. O modelo nos deu 'Cluster 0', 'Cluster 1', 'Cluster 2', 'Cluster 3'. E da√≠? Isso n√£o diz nada para o RH.\n",
        "N√≥s precisamos *humanizar* esses n√∫meros. Vamos 'tirar a m√©dia' de cada cluster.\n",
        "* Cluster 0: M√©dia de Sal√°rio ALTA, m√©dia de Satisfa√ß√£o ALTA.\n",
        "* Cluster 1: M√©dia de Sal√°rio BAIXA, m√©dia de Satisfa√ß√£o BAIXA.\n",
        "Agora sim! Podemos dar nomes a eles.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "A interpreta√ß√£o dos clusters (o passo mais crucial) √© feita analisando os centroides de cada cluster. A forma mais f√°cil de fazer isso √© usando `.groupby()` no DataFrame original (com os valores reais, *n√£o* escalados) pela coluna 'Cluster' que criamos, e calculando a `.mean()` de cada feature.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "1-f9Vg2V_SI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupar pela coluna 'Cluster' e calcular a m√©dia das features que usamos\n",
        "# (Inclu√≠mos 'pediu_demissao' para ver o risco de turnover de cada persona!)\n",
        "features_para_analise = features_para_cluster + ['pediu_demissao']\n",
        "\n",
        "# Usamos .drop() para remover colunas de texto que n√£o podem ter m√©dia\n",
        "df_personas = df_original_com_clusters.drop(columns=['departamento']).groupby('Cluster').mean()\n",
        "\n",
        "# Adicionar o tamanho de cada cluster para contexto\n",
        "df_personas['Tamanho (N)'] = df_original_com_clusters['Cluster'].value_counts()\n",
        "\n",
        "print(\"--- Tabela de Personas (M√©dias por Cluster) ---\")\n",
        "# Formatando a tabela para melhor visualiza√ß√£o\n",
        "print(df_personas.style.format({\n",
        "    'salario': 'R$ {:,.2f}',\n",
        "    'satisfacao': '{:.2%}',\n",
        "    'tempo_empresa': '{:.1f} anos',\n",
        "    'avaliacao_performance': '{:.2%}',\n",
        "    'pediu_demissao': '{:.2%}'\n",
        "}).background_gradient(cmap='viridis', subset=['salario', 'satisfacao', 'avaliacao_performance']).background_gradient(cmap='coolwarm', subset=['pediu_demissao']))"
      ],
      "metadata": {
        "id": "7mZNSQ5w_VO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado (A Tabela de Personas):**\n",
        "\"Esta tabela √© o resultado final do projeto. Agora podemos dar os nomes:\n",
        "* **Cluster 0 (Ex):** Sal√°rio ALTO, Satisfa√ß√£o ALTA, Tempo de Empresa ALTO, Turnover BAIXO. -> **Persona: 'Veteranos Engajados'**.\n",
        "* **Cluster 1 (Ex):** Sal√°rio BAIXO, Satisfa√ß√£o BAIXA, Tempo de Empresa BAIXO, Turnover ALTO. -> **Persona: 'Novatos em Risco'**.\n",
        "* **Cluster 2 (Ex):** Sal√°rio M√âDIO, Satisfa√ß√£o M√âDIA, Perf. ALTA, Turnover M√âDIO. -> **Persona: 'Talentos Estagnados'**.\n",
        "* ... e assim por diante.\""
      ],
      "metadata": {
        "id": "mHCVNr1D_Yq5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conceito 6 (B√¥nus): Visualiza√ß√£o dos Clusters (2D)\n",
        "\n",
        "üß† **Intui√ß√£o:**\n",
        "\"Uma imagem vale mais que mil palavras. Vamos 'desenhar' os clusters. Escolhemos as duas features mais importantes (ex: 'salario' e 'satisfacao') e plotamos um gr√°fico de dispers√£o (scatterplot), colorindo cada ponto com a cor do seu cluster. Isso ajuda o RH a *ver* as 'bolhas' de personas que acabamos de identificar.\"\n",
        "\n",
        "üéì **Defini√ß√£o T√©cnica:**\n",
        "A visualiza√ß√£o de clusters √© uma etapa qualitativa de valida√ß√£o. Como nossos dados t√™m muitas dimens√µes (ex: 5 ou 6 features), n√£o podemos visualiz√°-los diretamente.\n",
        "A t√©cnica mais simples √© plotar um gr√°fico de dispers√£o 2D usando as duas features mais interpret√°veis (ou as mais importantes, segundo o `feature_importance_` de um modelo Random Forest).\n",
        "Usamos o `hue='Cluster'` (do Seaborn) para mapear a coluna de r√≥tulo do cluster (0, 1, 2, 3) a um esquema de cores, permitindo-nos ver a separa√ß√£o (ou sobreposi√ß√£o) dos grupos.\n",
        "\n",
        "üç≥ **Receita:**"
      ],
      "metadata": {
        "id": "3aE1HUDH_acv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 7))\n",
        "sns.scatterplot(\n",
        "    data=df_original_com_clusters,\n",
        "    x='salario',\n",
        "    y='satisfacao',\n",
        "    hue='Cluster', # A m√°gica acontece aqui\n",
        "    palette='viridis', # Esquema de cores\n",
        "    s=100, # Tamanho dos pontos\n",
        "    alpha=0.7 # Transpar√™ncia\n",
        ")\n",
        "plt.title('Clusters de Funcion√°rios (Personas)')\n",
        "plt.xlabel('Sal√°rio')\n",
        "plt.ylabel('N√≠vel de Satisfa√ß√£o')\n",
        "plt.legend(title='Persona (Cluster)')\n",
        "plt.grid(linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "viiFJeb8_ghj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìä **Resultado:**\n",
        "\"O gr√°fico mostra visualmente as 'fronteiras' que o K-Means encontrou. Idealmente, veremos grupos de cores distintas (Ex: um 'bols√£o' verde no canto inferior esquerdo, um 'bols√£o' roxo no canto superior direito). Se as cores estiverem muito misturadas, isso refor√ßa um Silhouette Score baixo e sugere que, pelo menos *nestas duas dimens√µes*, os grupos n√£o s√£o bem definidos.\""
      ],
      "metadata": {
        "id": "LJY0fLrK_yIV"
      }
    }
  ]
}